from celery import Celery
import zipfile
import json
import logging
import sys
import pathlib
import io
import datetime
import re
from pathlib import Path

logging.getLogger('pymongo').setLevel(logging.INFO)


# temporary fix for importing module problems
# TODO change background tasks to module
pathRoot = pathlib.Path(__file__).parents[1]
sys.path.append(str(pathRoot))

from pydantic import BaseModel, Field
from fairscape_mds.config import get_fairscape_config
from fairscape_mds.utilities.utils import parseArk
from fairscape_mds.models.user import UserLDAP
from fairscape_mds.models.dataset import DatasetDistribution, MinioDistribution
from fairscape_mds.models.rocrate import (
    ExtractCrate,
    DeleteExtractedCrate,
    GetMetadataFromCrate,
    StreamZippedROCrate,
    ROCrate,
    ROCrateDistribution
)
from fairscape_mds.auth.ldap import getUserByCN

from typing import List, Dict, Optional
from uuid import UUID, uuid4


# setup logging
#logging.basicConfig(stream="", level=logging.INFO)
pathlib.Path('/tmp/jobs').mkdir(exist_ok=True)
fairscapeLogFolder = pathlib.Path("/tmp/logs")
fairscapeLogFolder.mkdir(exist_ok=True)

fairscapeWorkerLogfile = fairscapeLogFolder / 'worker.log'
workerLogHandler = logging.FileHandler(fairscapeWorkerLogfile)

backgroundTaskLogger = logging.getLogger("worker")
backgroundTaskLogger.addHandler(workerLogHandler)


# setup clients
fairscapeConfig = get_fairscape_config()
brokerURL = fairscapeConfig.redis.getBrokerURL()

celeryApp = Celery()
celeryApp.conf.broker_url = brokerURL

def serializeTimestamp(time):
    if time:
        return time.timestamp()
    else:
        return None

class ROCrateUploadJob(BaseModel):
    userCN: str
    transactionFolder: str
    zippedCratePath: str
    timeStarted: datetime.datetime | None = Field(default=None)
    timeFinished: datetime.datetime | None = Field(default=None)
    progress: float = Field(default=0)
    status: Optional[str] = Field(default='in progress')
    completed: Optional[bool] = Field(default=False)
    success: Optional[bool] = Field(default=False)
    processedFiles: List[str] = Field(default=[])
    identifiersMinted: List[str] = Field(default=[])
    error: str | None = Field(default=None)


def createUploadJob(
        asyncJobCollection,
        userCN: str,
        transactionFolder: str, 
        zippedCratePath: str,
        ):
    ''' Insert a record into mongo for the submission of a job.

    Keyword arguments:
    transactionFolder -- (str) the UUID representing the unique path in minio
    zippedCratePath   -- (str) the filename of the zipped crate contents
    '''

    # setup job model
    uploadJobInstance = ROCrateUploadJob(
        userCN = userCN,
        transactionFolder=transactionFolder,
        zippedCratePath=zippedCratePath,
        timeStarted= datetime.datetime.now(tz=datetime.timezone.utc),
    )

    insertResult = asyncJobCollection.insert_one(
            uploadJobInstance.model_dump()
            )

    return uploadJobInstance 


def getUploadJob(
        asyncJobCollection,
        transactionFolder: str,
    ):
    ''' Return a upload Job record from mongo by the job UUID generated by celery.

    Keyword arguments:
    transactionFolder -- (str) the UUID representing the unique path in minio
    zippedCratePath   -- (str) the filename of the zipped crate contents
    '''

    jobMetadata = asyncJobCollection.find_one(
        {"transactionFolder": transactionFolder},
        { "_id": 0}
    )

    if jobMetadata:
        return ROCrateUploadJob.model_validate(jobMetadata)
    else:
        return None


def updateUploadJob(transactionFolder: str, update: Dict):
    ''' Update async job using the transactionFolder as the primary key

    :param str transactionFolder: the UUID primary key representing the upload job
    :param dict update: metadata to update the upload job document
    '''

    asyncCollection.update_one(
            {
                "transactionFolder": transactionFolder,
                }, 
            {"$set": update}
            )


def ProcessMetadata(roCrateMetadata, userCN: str, zipname: str):
    """ Function for processing metadata
    """ 
    crateArk = parseArk(roCrateMetadata["@id"])

    # Add distribution information if not present
    if 'distribution' not in roCrateMetadata:
        crate_name = Path(zipname).stem  # Get filename without extension
        object_path = f"{transactionFolder}/{crate_name}"

        roCrateMetadata['distribution'] = {
            "archivedROCrateBucket": fairscapeConfig.minio.rocrate_bucket,
            "archivedObjectPath": pathlib.Path(fairscapeConfig.minio.rocrate_bucket_path) / userCN / filePath / zipname
        }
        # set download link to https download link
        roCrateMetadata['contentURL'] = f"{fairscapeConfig.url}/rocrate/download/{rocrateGUID}" 

    roCrateMetadata['uploadDate'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    if crateArk is None:
        # TODO assign new identifiers
        pass
    else:
        roCrateMetadata["@id"] = crateArk

    # TODO reassign identifiers if there is conflict
    for crateElement in roCrateMetadata["@graph"]:
        elementArk = parseArk(crateElement["@id"])
        if elementArk is None:
            pass
        else:
            crateElement["@id"] = elementArk



def relativeCratePath(nestedFile: str, crateStem: str):
	""" Utility for generating nested filepaths relative to the crate folder
	"""

	nestedFilepath = pathlib.Path(nestedFile)
	relativePath = pathlib.Path(nestedFilepath.name)
	nextLevel = nestedFilepath.parent
	relativePath = nextLevel.name / relativePath 

	nestedDepth = 1
	if nextLevel.name != crateStem:

		finished = False
		while finished != True or nestedDepth >= 10:
			nextLevel= nextLevel.parent
			relativePath = nextLevel.name / relativePath 
			print(relativePath)

			nestedDepth + 1

			if nextLevel.name == crateStem:
				finished = True
		
	return relativePath 



@celeryApp.task(name='async-register-ro-crate')
def AsyncRegisterROCrate(userCN: str, transactionFolder: str, filePath: str):
    """
    Background task for processing Zipped ROCrates.
    :param str userCN: Current User's CN uploading the ROCrate
    :param str transactionFolder: UUID folder representing the unique path in minio
    :param str filePath: The filename of the zipped crate contents
    """

    # connect to ldap and get user
    ldapConnection = fairscapeConfig.ldap.connectAdmin()
    currentUser = getUserByCN(ldapConnection, userCN)
    ldapConnection.unbind()

    minioClient = fairscapeConfig.minio.CreateClient()
    mongoClient = fairscapeConfig.mongo.CreateClient()

    mongoDB = mongoClient[fairscapeConfig.mongo.db]
    asyncCollection = mongoDB[fairscapeConfig.mongo.async_collection]

    # download crate from minio and store in a temporary file
    # write zip to temporary file and alter metadata
    jobDir = pathlib.Path(f"/tmp/jobs/{transactionFolder}")
    jobDir.mkdir(exist_ok=True)
    tmpZipFilepath = jobDir / pathlib.Path(filePath).name

    try:
        objectResponse = minioClient.fget_object(
            bucket_name=fairscapeConfig.minio.rocrate_bucket, 
            object_name=filePath,
            file_path=str(tmpZipFilepath)
        )
    except Exception as minioException:
        backgroundTaskLogger.error(
            f"transaction: {str(transactionFolder)}" +
            "\tmessage: failed to read minio object" + f"\terror: {str(minioException)}"
        )
        updateUploadJob(
            transactionFolder, 
            {
                "completed": True,
                "success": False,
                "error": f"Failed to read minio Object \terror: {str(minioException)}",
                "status": "Failed"
            }
        )
        return False
    #finally:
    #    objectResponse.close()
    #    objectResponse.release_conn()

    jobDir = pathlib.Path(f"/tmp/jobs/{transactionFolder}")
    extractDir = jobDir / 'extracts'
    extractDir.mkdir(exist_ok=True)

    # try reading the tmp zip filepath
    with tmpZipFilepath.open("rb") as tmpZipFileObj:
        zipCrate = zipfile.ZipFile(tmpZipFileObj)
        zipCrate.extractall(path=extractDir)

        backgroundTaskLogger.info(
            f"transaction: {str(transactionFolder)}" +
            "\tmessage: extracted files"  
        )

    # find the ro-crate-metadata.json file and read it in
    metadataSearch = list(pathlib.Path(extractDir).rglob("*ro-crate-metadata.json"))
    if len(metadataSearch) != 1:
        raise Exception("ro-crate-metadata.json not found in crate")	

    crateMetadataPath = metadataSearch[0]

    with crateMetadataPath.open("r") as crateMetadataFileObj:
        crateMetadata = json.load(crateMetadataFileObj)

    
    # edit metadata
    # - format identifiers
    # - add distribution
    
    
    # TODO reassign identifiers if there is conflict
    crateGUID = parseArk(crateMetadata["@id"])

    # TODO if no ROCrate ARK is assigned 
    # if crateMetadata.get("@id") is None:
    #    pass

    # Add distribution information if not present
    crateStem = pathlib.Path(filePath).stem
    if crateMetadata.get('distribution') is None:
        zipUploadPath = pathlib.Path(fairscapeConfig.minio.rocrate_bucket_path) / userCN / 'rocrates' / pathlib.Path(filePath).name
        crateMetadata['distribution'] = {
            "archivedROCrateBucket": fairscapeConfig.minio.rocrate_bucket,
            "archivedObjectPath": str(zipUploadPath)
        }
        # set download link to https download link
        crateMetadata['contentURL'] = f"{fairscapeConfig.url}/rocrate/download/{crateGUID}" 

    crateMetadata['uploadDate'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


    for crateElement in crateMetadata["@graph"]:
        #if elementArk is None:
        #    pass
        elementArk = parseArk(crateElement["@id"])
        crateElement['isPartOf'] = {"@id": crateGUID}


    
    # persist changes to extract dir 
    with crateMetadataPath.open("w") as crateMetadataFileObj:
        json.dump(crateMetadata, crateMetadataFileObj, indent=2)

    # overwrite zipfile    
    with zipfile.ZipFile(tmpZipFilepath, mode="w") as zipCrate:
        
        crateName = pathlib.Path(filePath).name
        contentDir = extractDir / crateStem

        for crateElement in contentDir.rglob("*"):
            keyName = crateElement.relative_to(
                f'/tmp/jobs/{transactionFolder}/extracts/{crateStem}'
            )
            zipCrate.write(filename=crateElement, arcname=keyName)

    # write final rocrate into archive at the path   
    # / default / {userCN} / rocrates / crateName
    try:
        objectResponse = minioClient.fput_object(
            bucket_name=fairscapeConfig.minio.rocrate_bucket, 
            object_name=str(zipUploadPath),
            file_path=str(tmpZipFilepath)
        )
        
        backgroundTaskLogger.info(
            f"transaction: {str(transactionFolder)}" +
            "\tmessage: uploaded new zip" 
            )

    except Exception as e:
        backgroundTaskLogger.error(
            f"transaction: {str(transactionFolder)}" +
            "\tmessage: error uploading processed ROCrate Archive" +
            f"\texception: {str(e)}"
            )

    # upload extracted files to datasets

    # TODO preform before finalizing 
    # filter out all datasets
    crateDatasets = filter(
        lambda crateElem: crateElem.get("@type") == "EVI:Dataset" and  crateElem.get("contentUrl") is not None,
        crateMetadata['@graph']
        )

    for datasetElem in crateDatasets:

        # file to read from within the zipfile 
        contentURL = datasetElem['contentUrl']
        sourcePath = pathlib.Path(contentURL.lstrip('file:///'))



        # compute relative crate path
        # this will give elements a path in minio preserving the structure of the rocrate
        # files will have relative path similar to
        #  {ro_crate_name} / *** / {filename}
        # starting from the deepest element breaking at the level of the rocrate
        folderNames= str(sourcePath).split('/')
        folderNames.reverse()

        relativePath = pathlib.Path(folderNames[0])

        for nested in folderNames[1::]:
            relativePath = nested / relativePath
            if nested == crateStem:
                break

        
        uploadPath = pathlib.Path(fairscapeConfig.minio.default_bucket_path) / currentUser.cn / 'datasets' / relativePath
        tmpFilePath = pathlib.Path('/tmp/jobs/') / transactionFolder / 'extracts' / relativePath


        backgroundTaskLogger.info(                
            f"transaction: {str(transactionFolder)}" +
            f"\tuploadPath: {str(uploadPath)}" +
            f"\ttmpFilePath: {str(tmpFilePath)}" +
            "\tmessage: uploading dataset" 
            )


        try:
            uploadResult = minioClient.fput_object(
                    bucket_name=fairscapeConfig.minio.default_bucket,
                    object_name=str(uploadPath),
                    file_path=str(tmpFilePath),
                    metadata={
                        "guid": datasetElem.get("@id"),
                        "owner": userCN
                        }
                    )
        except Exception as e:
            backgroundTaskLogger.error(                
            f"transaction: {str(transactionFolder)}" +
            f"\tuploadPath: {str(uploadPath)}" +
            f"\ttmpFilePath: {str(tmpFilePath)}" +
            "\tmessage: error uploading processed crate DATASETS" +
            f"\texception: {str(e)}"
            )


        # add archive to datasetElem metadata

        # TODO set download link relative to fairscape
        datasetElem['distribution'] = {

        }
        # TODO check that dataset enpoint works and is accurate
        datasetElem['contentUrl']=f"{fairscapeConfig.url}/dataset/download/{datasetElem['@id']}"
        

        # publish metadata





    # close clients
    mongoClient.close()


    return crateMetadata



def OldExtract():
    # extracting crate from path
    try:
        #roCrateMetadata = ExtractCrate(
        #    fairscapeConfig=fairscapeConfig,
        #    userCN=userCN,
        #    transactionFolder=transactionFolder,
        #    objectPath=filePath
        #)
        pass

        # update the uploadJob record
        #if roCrateMetadata is None:
        #    updateUploadJob(
        #        transactionFolder,
        #        {
        #            "completed": True,
        #            "success": False,
        #            "error": "error reading ro-crate-metadata",
        #            "status": "Failed"
        #        }
        #    )
        # return False
    except:
        updateUploadJob(
            transactionFolder,
            {
                "completed": True,
                "success": False,
                "error": "No ro-crate-metadata.json in zip file",
                "status": "Failed"
            }
        )
        return False


    # Process rocrate metadata
    updateUploadJob(
        transactionFolder,
        {"status": "minting identifiers"}
    )

    # TODO reason the rocrate metadata locally 
    # TODO reason over the rocrate metadata globally
    
    # TODO overwrite the rocrate metadata
    # overwriteZippedCrateMetadata(
    #    crateMetadata = rocrateMetadata,
    #    transactionFolder= transactionFolder,
    #)


    try:
        publishMetadata = PublishMetadata(
            currentUser=currentUser,
            rocrateJSON=roCrateMetadata,
            transactionFolder=transactionFolder,
            rocrateCollection=rocrateCollection,
            identifierCollection=identifierCollection,
        )
    except:
        updateUploadJob(
            transactionFolder,
            {
                "status": "Failed",
                "timeFinished": datetime.datetime.now(tz=datetime.timezone.utc),
                "completed": True,
                "success": False,
                "error": "Crate already exists on Fairscape."
            }
        )
        return False

    if publishMetadata is None:
        updateUploadJob(
            transactionFolder,
            {
                "status": "Failed",
                "timeFinished": datetime.datetime.now(tz=datetime.timezone.utc),
                "completed": True,
                "success": False,
            }
        )
        return False
    else:
        backgroundTaskLogger.info(
            f"transaction: {str(transactionFolder)}\t" +
            "message: task succeeded"
        )
        updateUploadJob(
            transactionFolder,
            {
                "status": "Finished",
                "timeFinished": datetime.datetime.now(tz=datetime.timezone.utc),
                "completed": True,
                "success": True,
                "identifiersMinted": publishMetadata
            }
        )
        return True


 



if __name__ == '__main__':
    args = ['worker', '--loglevel=INFO']
    celeryApp.worker_main(argv=args)

